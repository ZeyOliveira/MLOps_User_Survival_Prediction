# üöÄ User Survival Prediction: Um Pipeline MLOps Completo com GCP, Airflow, Redis e Monitoramento! üìä

## Vis√£o Geral do Projeto

Este projeto implementa uma solu√ß√£o de Machine Learning (ML) ponta-a-ponta para prever a sobreviv√™ncia de indiv√≠duos no desastre do Titanic. O foco principal √© demonstrar um pipeline MLOps robusto, que abrange desde a ingest√£o de dados em nuvem at√© o monitoramento cont√≠nuo do modelo em produ√ß√£o, garantindo automa√ß√£o, escalabilidade e observabilidade.

Desenvolvido como parte dos meus estudos em Ci√™ncia de Dados, com √™nfase em Power BI, Excel e SQL, este projeto consolida conhecimentos em engenharia de dados, pr√©-processamento, treinamento de modelos e as melhores pr√°ticas de MLOps.

## ÔøΩÔøΩ Destaques MLOps e Tecnol√≥gicos

*   **Automa√ß√£o End-to-End:** Orquestra√ß√£o completa do pipeline de ML com Apache Airflow.
*   **Infraestrutura Cloud:** Ingest√£o de dados a partir do Google Cloud Storage (GCS).
*   **Feature Store:** Utiliza√ß√£o do Redis como um Feature Store de baixa lat√™ncia para features pr√©-processadas.
*   **Servimento de Modelo:** Aplica√ß√£o Flask para exposi√ß√£o do modelo via API web e interface de usu√°rio.
*   **Monitoramento Ativo:** Detec√ß√£o de *Data Drift* em tempo real com Alibi-Detect.
*   **Observabilidade:** Monitoramento de m√©tricas com Prometheus e visualiza√ß√£o em dashboards no Grafana.
*   **Versionamento:** Controle de vers√£o de c√≥digo (Git/GitHub) e dados/artefatos.

## üß† Arquitetura do Sistema

A arquitetura do projeto foi projetada para ser modular e extens√≠vel, integrando diversas ferramentas em um fluxo de trabalho coeso:

```
                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                              ‚îÇ    Google Cloud   ‚îÇ
                              ‚îÇ (Bucket p/ CSV)   ‚îÇ
                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                      ‚îÇ Ingest√£o
                                      ‚ñº
                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                      ‚îÇ             Pipeline MLOps (Airflow DAG)      ‚îÇ
                      ‚îÇ (Orquestra: Ingest√£o -> Pr√©-processamento -> Treinamento) ‚îÇ
                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                         ‚îÇ
               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
               ‚ñº                         ‚ñº                         ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ DAG Ingest√£o (Airflow)‚îÇ   ‚îÇ  M√≥dulo Python  ‚îÇ   ‚îÇ   M√≥dulo Python      ‚îÇ
    ‚îÇ (GCS -> PostgreSQL)   ‚îÇ   ‚îÇ (DataIngestion.py) ‚îÇ   ‚îÇ (DataProcessing.py)  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ                          ‚îÇ                       ‚îÇ
               ‚ñº                          ‚ñº                       ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ    PostgreSQL   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ    CSVs Locais  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ     Redis FS    ‚îÇ
    ‚îÇ (Tabela Titanic)‚îÇ       ‚îÇ (train.csv, test.csv) ‚îÇ   ‚îÇ (Features Prontas)‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                 ‚îÇ
                                                                 ‚ñº
                                                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                                        ‚îÇ   M√≥dulo Python   ‚îÇ
                                                        ‚îÇ (ModelTraining.py) ‚îÇ
                                                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                 ‚îÇ
                                                                 ‚ñº
                                                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                                        ‚îÇ Modelo Treinado   ‚îÇ
                                                        ‚îÇ (Salvo em Artefatos) ‚îÇ
                                                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                 ‚îÇ
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ                                                          ‚îÇ                                                  ‚îÇ
      ‚ñº                                                          ‚ñº                                                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Aplica√ß√£o Flask ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ Previs√µes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  Alibi-Detect             ‚îÇ                        ‚îÇ Prometheus & Grafana      ‚îÇ
‚îÇ (UI Local)      ‚îÇ                               ‚îÇ (Detec√ß√£o de Data Drift)  ‚îÇ                        ‚îÇ (Monitoramento de M√©tricas) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üõ† Tecnologias Utilizadas

*   **Linguagem:** Python (3.12+)
*   **Orquestra√ß√£o:** Apache Airflow (via Astro CLI)
*   **Nuvem:** Google Cloud Platform (GCS para armazenamento de dados brutos)
*   **Banco de Dados:** PostgreSQL (armazenamento intermedi√°rio de dados)
*   **Feature Store:** Redis (para acesso de baixa lat√™ncia √†s features)
*   **Manipula√ß√£o de Dados:** Pandas, NumPy
*   **Machine Learning:** Scikit-learn (modelo, pr√©-processamento), Imblearn (SMOTE para balanceamento)
*   **Detec√ß√£o de Drift:** Alibi-Detect (KSDrift)
*   **Monitoramento:** Prometheus (coleta de m√©tricas), Grafana (visualiza√ß√£o de dashboards)
*   **Desenvolvimento Web:** Flask (API e UI para o modelo)
*   **Controle de Vers√£o:** Git, GitHub
*   **Containeriza√ß√£o:** Docker, Docker Compose

## ÔøΩÔøΩ Componentes Chave do Pipeline

1.  **`dags/extract_data_from_gcp.py` (DAG de Ingest√£o de Dados Brutos)**
    *   **Fun√ß√£o:** Orquestra a extra√ß√£o do arquivo `Titanic-Dataset.csv` de um bucket no GCS, faz um pr√©-processamento leve (ETL) e carrega os dados brutos na tabela `titanic` em um banco de dados PostgreSQL local rodando num conteiner Docker.
    *   **Tecnologias:** Apache Airflow, `apache-airflow-providers-google`, `apache-airflow-providers-postgres`.

2.  **`src/data_ingestion.py` (Script de Prepara√ß√£o Inicial de Dados)**
    *   **Fun√ß√£o:** Conecta ao PostgreSQL, extrai a tabela `titanic` como DataFrame, divide-a em conjuntos de treino (80%) e teste (20%) com `random_state=42`, e salva-os como arquivos CSV (`train.csv`, `test.csv`) no disco local.
    *   **Tecnologias:** Pandas, `psycopg2`, Scikit-learn.

3.  **`src/feature_store.py` (M√≥dulo de Feature Store com Redis)**
    *   **Fun√ß√£o:** Atua como um *Feature Store* simples, fornecendo m√©todos para conectar ao Redis, serializar features (JSON) de entidades e armazen√°-las/recuper√°-las de forma individual ou em lote. Projetado para baixa lat√™ncia.
    *   **Tecnologias:** Redis rodando dentro do Docker.

4.  **`src/data_processing.py` (M√≥dulo de Pr√©-processamento, Balanceamento, Feature Engineering, Encoding e Armazenamento de Features)**
    *   **Fun√ß√£o:** Carrega os CSVs de treino e teste, executa limpeza de dados, preenchimento de valores ausentes, codifica√ß√£o de vari√°veis categ√≥ricas, engenharia de novas features (`Familysize`, `HasCabin`, `Title`, `Pclass_Fare`, `Age_Fare`), tratamento de desbalanceamento usando SMOTE nos dados de treino, e finalmente armazena as features processadas no Redis Feature Store.
    *   **Tecnologias:** Pandas, Scikit-learn, Imblearn, `RedisFeatureStore`.

5.  **`src/model_training.py` (M√≥dulo de Treinamento do Modelo)**
    *   **Fun√ß√£o:** Recupera as features processadas e balanceadas do Redis Feature Store, busca os melhores hyperpar√¢metros usando `RandomizedSearchCV` treina um modelo de Machine Learning `RandomForestClassifier` para prever a sobreviv√™ncia, avalia seu desempenho e salva o modelo treinado (ex: `random_forest_model.pkl`) no diret√≥rio `artifacts/models/`.
    *   **Tecnologias:** Scikit-learn, `RedisFeatureStore`.

6.  **`pipeline/training_pipeline.py` (Pipeline Principal do MLOps)**
    *   **Fun√ß√£o:** Orquestra a execu√ß√£o sequencial de todas as etapas do pipeline: Ingest√£o de Dados Brutos (via `data_ingestion.py`), Pr√©-processamento/Feature Engineering/Balanceamento (`data_processing.py`) e Treinamento do Modelo (`model_training.py`).
    *   **Tecnologias:** Apache Airflow, Feature Store, logger, CustomException.

7.  **`application.py` (Servidor Flask para Servir o Modelo e Monitorar Drift)**
    *   **Fun√ß√£o:** Exp√µe o modelo de ML treinado via uma API web e interface de usu√°rio. Recebe inputs do usu√°rio, faz previs√µes e, crucialmente, monitora a qualidade dos dados de entrada em tempo real.
    *   **Tecnologias:** Flask, `Alibi-Detect` (KSDrift), `prometheus_client`, `Grafana`, `RedisFeatureStore`, Scikit-learn.
    *   **Rotas:**
        *   `/`: Renderiza o formul√°rio de previs√£o (`index.html`).
        *   `/predict` (POST): Processa inputs, detecta drift, faz previs√£o e exibe resultado.
        *   `/metrics`: Exp√µe m√©tricas de Prometheus (`prediction_count`, `drift_count`).

## üöÄ Como Executar o Projeto Localmente

Siga estes passos para configurar e executar todo o pipeline em sua m√°quina local.

### Pr√©-requisitos

*   Docker e Docker Compose
*   Python 3.12+
*   Astro CLI (para gerenciar o ambiente Airflow)
*   Uma conta GCP com um bucket configurado e uma chave de conta de servi√ßo (JSON) para acesso ao GCS.

### Configura√ß√£o

1.  **Clone o Reposit√≥rio:**
    ```bash
    git clone https://github.com/ZeyOliveira/MLOps_User_Survival_Prediction.git
    cd user_survival_prediction
    ```

2.  **Configura√ß√£o do GCP:**
    *   Certifique-se de ter um bucket no GCP com o arquivo `Titanic-Dataset.csv`.
    *   Crie uma chave de conta de servi√ßo com permiss√µes de leitura para o bucket e salve o arquivo JSON resultante em `include/gcp_key.json` dentro do seu projeto. (Crie a pasta `include` se ela n√£o existir).

3.  **Configura√ß√£o Astro CLI e Docker Compose:**
    *   Inicialize o ambiente Astro Airflow:
        ```bash
        astro dev init
        ```
    *   O Airflow usar√° o `requirements.txt` para instalar as depend√™ncias. Verifique se ele cont√©m todas as bibliotecas necess√°rias.
    *   **Ajuste o `docker-compose.yaml`:**
        *   Certifique-se de que o `docker-compose.yml` inclua servi√ßos, **Prometheus** e **Grafana**, al√©m dos servi√ßos padr√£o do Astro Airflow. Exemplo de estrutura no `docker-compose.yaml`:
            ```yaml            
            prometheus:
              image: prom/prometheus:latest
              command: --config.file=/etc/prometheus/prometheus.yml
              ports:
                - "9090:9090"
              volumes:
                - ./prometheus.yml:/etc/prometheus/prometheus.yml # Seu arquivo de config prometheus
            
            grafana:
              image: grafana/grafana:latest
              ports:
                - "3000:3000"
              environment:
                GF_SECURITY_ADMIN_USER: admin
                GF_SECURITY_ADMIN_PASSWORD: admin # Mude para uma senha segura em produ√ß√£o
              volumes:
                - grafana_data:/var/lib/grafana
            
            volumes:
              postgres_data:
              grafana_data:
            ```
        *   Crie um arquivo `prometheus.yml` na raiz do seu projeto com o seguinte conte√∫do para que o Prometheus possa "raspar" as m√©tricas do seu aplicativo Flask:
            ```yaml
            global:
              scrape_interval: 15s # By default, scrape targets every 15 seconds.
            
            scrape_configs:
              - job_name: 'flask-app-metrics'
                static_configs:
                  - targets: ['host.docker.internal:8000'] # Para Docker no Windows/Mac, use 'host.docker.internal'
                                                           # Para Linux, pode ser necess√°rio usar o IP do host ou um alias de rede.
            ```

4.  **Inicie os Servi√ßos Docker:**
    ```bash
    docker-compose up -d
    ```
    Isso iniciar√° Prometheus, Grafana.

5.  **Inicie o Ambiente Airflow:**
    ```bash
    astro dev start
    ```
    Acesse a UI do Airflow em `http://localhost:8080`.

6.  **Configure Conex√µes no Airflow:**
    *   Na UI do Airflow, v√° em `Admin > Connections` e crie:
        *   Uma conex√£o `google_cloud_default` usando o tipo `Google Cloud` e apontando para o arquivo de chave JSON que voc√™ salvou em `include/gcp_key.json`.
        *   Uma conex√£o `postgres_default` usando o tipo `Postgres`, Host `postgres` (nome do servi√ßo Docker), Schema `user_survival_db`, Login `postgres`, Password `postgres`.

7.  **Habilite e Rode a DAG Principal:**
    *   Na UI do Airflow, procure pela DAG `extract_data_from_gcp.py` (ou o nome que voc√™ deu √† sua DAG principal).
    *   Ative-a (toggle).
    *   Acione-a manualmente para iniciar o pipeline completo.
    *   Ou rode o arquivo `setup_connections_astro.py`, para contruir a DAG, com o arquivo `config.yml` com esse conte√∫do:
  ```
  connections:
    - conn_id: google_cloud_default
      conn_type: google_cloud_platform
      key_path: /usr/local/airflow/include/gcp-key.json
      schema: https://www.googleapis.com/auth/cloud-platform
  
    - conn_id: postgres_default
      conn_type: postgres
      host: localhost
      login: postgres
      password: postgres
      schema: public
      port: 5432
  ```

8.  **Execute o Aplicativo Flask:**
    *   Ap√≥s o pipeline do Airflow ter sido executado com sucesso e o modelo ter sido treinado e salvo (e as features no Redis), voc√™ pode iniciar o aplicativo Flask.
    *   Abra um novo terminal na raiz do projeto e execute:
        ```bash
        python application.py
        ```
    *   Acesse o aplicativo em `http://localhost:5000`.
    *   As m√©tricas do Prometheus estar√£o dispon√≠veis em `http://localhost:9090/`.
    *   Acesse o Grafana em `http://localhost:3000` (admin/admin) e configure uma fonte de dados Prometheus apontando para `http://prometheus:9090`. Crie um dashboard para visualizar `prediction_count_total` e `drift_count_total`.

## üì∏ Demonstra√ß√£o do Projeto

Aqui voc√™ encontrar√° capturas de tela e GIFs que ilustram o funcionamento do pipeline e da aplica√ß√£o.

*(**Instru√ß√µes para voc√™, Zeygler:** Substitua o texto abaixo pelas suas pr√≥prias imagens e GIFs de alta qualidade.)*

### 1. **Pipeline de Ingest√£o e Treinamento no Airflow**
*   Screenshot mostrando a DAG principal (`ml_pipeline_dag.py`) com todas as tarefas em estado "Success".
*   Screenshot dos logs de uma tarefa chave (ex: `data_processing`) mostrando a execu√ß√£o.
*   *Opcional:* GIF curto da DAG sendo acionada e as tarefas passando para verde.

### 2. **Dados no PostgreSQL**
*   Screenshot do DBeaver mostrando a tabela `titanic` populada ap√≥s a execu√ß√£o da DAG de ingest√£o, com uma query `SELECT * FROM titanic;`.

### 3. **Aplica√ß√£o Flask de Previs√£o**
*   Screenshot da p√°gina inicial (`http://localhost:5000`) com o formul√°rio vazio.
*   Screenshot do formul√°rio preenchido e o resultado da previs√£o (ex: "The prediction is: Survived").
*   GIF curto de voc√™ preenchendo o formul√°rio e clicando em "Predict", mostrando o resultado.

### 4. **Monitoramento com Prometheus e Grafana**
*   Screenshot da UI do Prometheus (`http://localhost:9090`) com uma query para `prediction_count_total` ou `drift_count_total` exibindo o valor.
*   Screenshot de um dashboard no Grafana (`http://localhost:3000`) que voc√™ criou, mostrando gr√°ficos de `prediction_count_total` e `drift_count_total` ao longo do tempo.
*   **üéâ Demonstra√ß√£o de Data Drift (O MAIS IMPACTANTE!):**
    *   GIF ou v√≠deo curto: Comece mostrando o dashboard do Grafana com `drift_count_total` baixo/zero.
    *   Em seguida, na aplica√ß√£o Flask, **insira dados de entrada deliberadamente "estranhos" ou muito diferentes** dos dados de refer√™ncia (ex: Idade = 1000, Tarifa = -500).
    *   Mostre o `drift_count_total` no Grafana incrementando ap√≥s essas submiss√µes, demonstrando que o Alibi-Detect identificou o desvio e o Prometheus registrou.

## ‚ú® MLOps em Destaque

Este projeto demonstra uma compreens√£o pr√°tica dos princ√≠pios de MLOps:

*   **Automa√ß√£o:** Todas as etapas do ciclo de vida do ML s√£o automatizadas via Airflow, reduzindo erros manuais e tempo de execu√ß√£o.
*   **Versionamento:** C√≥digo e dados s√£o versionados no GitHub, garantindo reprodutibilidade e rastreabilidade.
*   **Feature Store:** O Redis atua como um reposit√≥rio centralizado e eficiente para features, desacoplando a gera√ß√£o do consumo e garantindo consist√™ncia.
*   **Monitoramento e Observabilidade:** A integra√ß√£o com Prometheus e Grafana fornece visibilidade em tempo real sobre a sa√∫de do servi√ßo e o comportamento do modelo.
*   **Detec√ß√£o de Drift:** A implementa√ß√£o do Alibi-Detect oferece um mecanismo proativo para identificar quando o modelo pode estar se tornando obsoleto devido a mudan√ßas nos dados.
*   **Desacoplamento:** Componentes como o Feature Store e o servidor de modelo s√£o independentes, facilitando a manuten√ß√£o e a escalabilidade.

## üîÆ Pr√≥ximos Passos

*   **Integra√ß√£o com ChatGPT:** Melhorar a experi√™ncia do usu√°rio na aplica√ß√£o Flask, fornecendo explica√ß√µes mais ricas ou contexto adicional para as previs√µes usando uma API de linguagem natural.
*   **CI/CD:** Implementar pipelines de Integra√ß√£o Cont√≠nua e Entrega Cont√≠nua (CI/CD) para automatizar o deploy do c√≥digo.
*   **A/B Testing:** Adicionar funcionalidades para testar diferentes vers√µes do modelo em produ√ß√£o.
*   **Mais Modelos:** Explorar outros algoritmos de ML e comparar seu desempenho.
*   **Containeriza√ß√£o do Flask:** Criar um Dockerfile para o aplicativo Flask e integr√°-lo ao `docker-compose.yaml`.

---

**Conecte-se comigo:**

*   **LinkedIn:** https://www.linkedin.com/in/zeygleroliveira/
*   **GitHub:** https://github.com/ZeyOliveira
*   **Gmail:** zeyglerdasilva@gmail.com
